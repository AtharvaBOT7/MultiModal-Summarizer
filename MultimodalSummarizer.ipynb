{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08138e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydantic\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting pillow\n",
      "  Using cached pillow-11.2.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (8.9 kB)\n",
      "Collecting lxml\n",
      "  Using cached lxml-5.4.0-cp39-cp39-macosx_10_9_universal2.whl.metadata (3.5 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.9.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting unstructured[all-docs]\n",
      "  Downloading unstructured-0.17.2-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting chardet (from unstructured[all-docs])\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured[all-docs])\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured[all-docs])\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nltk (from unstructured[all-docs])\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting requests (from unstructured[all-docs])\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting beautifulsoup4 (from unstructured[all-docs])\n",
      "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting emoji (from unstructured[all-docs])\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dataclasses-json (from unstructured[all-docs])\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting python-iso639 (from unstructured[all-docs])\n",
      "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured[all-docs])\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm-:--:--\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numpy (from unstructured[all-docs])\n",
      "  Using cached numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting rapidfuzz (from unstructured[all-docs])\n",
      "  Downloading rapidfuzz-3.13.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting backoff (from unstructured[all-docs])\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: typing-extensions in ./multimodal/lib/python3.9/site-packages (from unstructured[all-docs]) (4.14.0)\n",
      "Collecting unstructured-client (from unstructured[all-docs])\n",
      "  Downloading unstructured_client-0.36.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting wrapt (from unstructured[all-docs])\n",
      "  Using cached wrapt-1.17.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting tqdm (from unstructured[all-docs])\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in ./multimodal/lib/python3.9/site-packages (from unstructured[all-docs]) (7.0.0)\n",
      "Collecting python-oxmsg (from unstructured[all-docs])\n",
      "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured[all-docs])\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting onnxruntime>=1.19.0 (from unstructured[all-docs])\n",
      "  Downloading onnxruntime-1.19.2-cp39-cp39-macosx_11_0_universal2.whl.metadata (4.5 kB)\n",
      "Collecting python-pptx>=1.0.1 (from unstructured[all-docs])\n",
      "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting effdet (from unstructured[all-docs])\n",
      "  Downloading effdet-0.4.1-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting pypandoc (from unstructured[all-docs])\n",
      "  Downloading pypandoc-1.15-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting pikepdf (from unstructured[all-docs])\n",
      "  Downloading pikepdf-9.8.1-cp39-cp39-macosx_14_0_arm64.whl.metadata (8.2 kB)\n",
      "Collecting google-cloud-vision (from unstructured[all-docs])\n",
      "  Downloading google_cloud_vision-3.10.2-py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting unstructured.pytesseract>=0.3.12 (from unstructured[all-docs])\n",
      "  Downloading unstructured.pytesseract-0.3.15-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pdfminer.six (from unstructured[all-docs])\n",
      "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting unstructured-inference>=0.8.10 (from unstructured[all-docs])\n",
      "  Downloading unstructured_inference-1.0.5-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting xlrd (from unstructured[all-docs])\n",
      "  Downloading xlrd-2.0.2-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting networkx (from unstructured[all-docs])\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pandas (from unstructured[all-docs])\n",
      "  Using cached pandas-2.3.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting pdf2image (from unstructured[all-docs])\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting openpyxl (from unstructured[all-docs])\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting python-docx>=1.1.2 (from unstructured[all-docs])\n",
      "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pypdf (from unstructured[all-docs])\n",
      "  Using cached pypdf-5.6.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting onnx>=1.17.0 (from unstructured[all-docs])\n",
      "  Downloading onnx-1.18.0-cp39-cp39-macosx_12_0_universal2.whl.metadata (6.9 kB)\n",
      "Collecting markdown (from unstructured[all-docs])\n",
      "  Using cached markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pi-heif (from unstructured[all-docs])\n",
      "  Downloading pi_heif-0.22.0-cp39-cp39-macosx_14_0_arm64.whl.metadata (6.5 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic)\n",
      "  Using cached pydantic_core-2.33.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.58.4-cp39-cp39-macosx_10_9_universal2.whl.metadata (106 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.7-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./multimodal/lib/python3.9/site-packages (from matplotlib) (25.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./multimodal/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./multimodal/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.23.0)\n",
      "Collecting protobuf>=4.25.1 (from onnx>=1.17.0->unstructured[all-docs])\n",
      "  Using cached protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.19.0->unstructured[all-docs])\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.19.0->unstructured[all-docs])\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.19.0->unstructured[all-docs])\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./multimodal/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx>=1.0.1->unstructured[all-docs])\n",
      "  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting python-multipart (from unstructured-inference>=0.8.10->unstructured[all-docs])\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting huggingface-hub (from unstructured-inference>=0.8.10->unstructured[all-docs])\n",
      "  Using cached huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting opencv-python!=4.7.0.68 (from unstructured-inference>=0.8.10->unstructured[all-docs])\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Collecting torch (from unstructured-inference>=0.8.10->unstructured[all-docs])\n",
      "  Using cached torch-2.7.1-cp39-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Collecting timm (from unstructured-inference>=0.8.10->unstructured[all-docs])\n",
      "  Downloading timm-1.0.15-py3-none-any.whl.metadata (52 kB)\n",
      "Collecting transformers>=4.25.1 (from unstructured-inference>=0.8.10->unstructured[all-docs])\n",
      "  Using cached transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting accelerate (from unstructured-inference>=0.8.10->unstructured[all-docs])\n",
      "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting scipy (from unstructured-inference>=0.8.10->unstructured[all-docs])\n",
      "  Using cached scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "Collecting pypdfium2 (from unstructured-inference>=0.8.10->unstructured[all-docs])\n",
      "  Downloading pypdfium2-4.30.1-py3-none-macosx_11_0_arm64.whl.metadata (48 kB)\n",
      "Collecting filelock (from transformers>=4.25.1->unstructured-inference>=0.8.10->unstructured[all-docs])\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers>=4.25.1->unstructured-inference>=0.8.10->unstructured[all-docs])\n",
      "  Using cached PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.25.1->unstructured-inference>=0.8.10->unstructured[all-docs])\n",
      "  Using cached regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.25.1->unstructured-inference>=0.8.10->unstructured[all-docs])\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.25.1->unstructured-inference>=0.8.10->unstructured[all-docs])\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub->unstructured-inference>=0.8.10->unstructured[all-docs])\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub->unstructured-inference>=0.8.10->unstructured[all-docs])\n",
      "  Downloading hf_xet-1.1.4-cp37-abi3-macosx_11_0_arm64.whl.metadata (879 bytes)\n",
      "Collecting jinja2 (from torch->unstructured-inference>=0.8.10->unstructured[all-docs])\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.19.0->unstructured[all-docs])\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->unstructured[all-docs])\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.19.0->unstructured[all-docs])\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->unstructured[all-docs])\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->unstructured[all-docs])\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured[all-docs])\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting torchvision (from effdet->unstructured[all-docs])\n",
      "  Using cached torchvision-0.22.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Collecting pycocotools>=2.0.2 (from effdet->unstructured[all-docs])\n",
      "  Downloading pycocotools-2.0.10-cp39-cp39-macosx_10_9_universal2.whl.metadata (1.3 kB)\n",
      "Collecting omegaconf>=2.0 (from effdet->unstructured[all-docs])\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.0->effdet->unstructured[all-docs])\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs])\n",
      "  Downloading google_api_core-2.25.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 (from google-cloud-vision->unstructured[all-docs])\n",
      "  Using cached google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-cloud-vision->unstructured[all-docs])\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs])\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs])\n",
      "  Using cached grpcio-1.73.0-cp39-cp39-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs])\n",
      "  Using cached grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs])\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs])\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs])\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->unstructured[all-docs])\n",
      "  Using cached charset_normalizer-3.4.2-cp39-cp39-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->unstructured[all-docs])\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->unstructured[all-docs])\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->unstructured[all-docs])\n",
      "  Downloading certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs])\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting webencodings (from html5lib->unstructured[all-docs])\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch->unstructured-inference>=0.8.10->unstructured[all-docs])\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in ./multimodal/lib/python3.9/site-packages (from markdown->unstructured[all-docs]) (8.7.0)\n",
      "Collecting click (from nltk->unstructured[all-docs])\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting joblib (from nltk->unstructured[all-docs])\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting et-xmlfile (from openpyxl->unstructured[all-docs])\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->unstructured[all-docs])\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->unstructured[all-docs])\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six->unstructured[all-docs])\n",
      "  Downloading cryptography-45.0.4-cp37-abi3-macosx_10_9_universal2.whl.metadata (5.7 kB)\n",
      "Collecting cffi>=1.14 (from cryptography>=36.0.0->pdfminer.six->unstructured[all-docs])\n",
      "  Using cached cffi-1.17.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting pycparser (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six->unstructured[all-docs])\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting Deprecated (from pikepdf->unstructured[all-docs])\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting olefile (from python-oxmsg->unstructured[all-docs])\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured[all-docs])\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting httpx>=0.27.0 (from unstructured-client->unstructured[all-docs])\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in ./multimodal/lib/python3.9/site-packages (from unstructured-client->unstructured[all-docs]) (1.6.0)\n",
      "Collecting requests-toolbelt>=1.0.0 (from unstructured-client->unstructured[all-docs])\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting anyio (from httpx>=0.27.0->unstructured-client->unstructured[all-docs])\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.27.0->unstructured-client->unstructured[all-docs])\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured[all-docs])\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./multimodal/lib/python3.9/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured[all-docs]) (1.3.0)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.27.0->unstructured-client->unstructured[all-docs])\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading unstructured-0.17.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp39-cp39-macosx_11_0_arm64.whl (1.9 MB)\n",
      "Using cached pillow-11.2.1-cp39-cp39-macosx_11_0_arm64.whl (3.0 MB)\n",
      "Using cached lxml-5.4.0-cp39-cp39-macosx_10_9_universal2.whl (8.1 MB)\n",
      "Using cached matplotlib-3.9.4-cp39-cp39-macosx_11_0_arm64.whl (7.8 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached contourpy-1.3.0-cp39-cp39-macosx_11_0_arm64.whl (249 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.58.4-cp39-cp39-macosx_10_9_universal2.whl (2.8 MB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached kiwisolver-1.4.7-cp39-cp39-macosx_11_0_arm64.whl (64 kB)\n",
      "Using cached numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\n",
      "Downloading onnx-1.18.0-cp39-cp39-macosx_12_0_universal2.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.19.2-cp39-cp39-macosx_11_0_universal2.whl (16.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl (425 kB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading unstructured_inference-1.0.5-py3-none-any.whl (48 kB)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "Using cached huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\n",
      "Downloading hf_xet-1.1.4-cp37-abi3-macosx_11_0_arm64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Using cached PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl (172 kB)\n",
      "Using cached regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading unstructured.pytesseract-0.3.15-py3-none-any.whl (14 kB)\n",
      "Downloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n",
      "Downloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
      "Using cached torch-2.7.1-cp39-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
      "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Downloading pycocotools-2.0.10-cp39-cp39-macosx_10_9_universal2.whl (153 kB)\n",
      "Downloading timm-1.0.15-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading google_cloud_vision-3.10.2-py3-none-any.whl (527 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.9/527.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.25.1-py3-none-any.whl (160 kB)\n",
      "Using cached google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Using cached grpcio-1.73.0-cp39-cp39-macosx_11_0_universal2.whl (10.6 MB)\n",
      "Downloading grpcio_status-1.73.0-py3-none-any.whl (14 kB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp39-cp39-macosx_10_9_universal2.whl (201 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp39-cp39-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Using cached pandas-2.3.0-cp39-cp39-macosx_11_0_arm64.whl (10.8 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cryptography-45.0.4-cp37-abi3-macosx_10_9_universal2.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cffi-1.17.1-cp39-cp39-macosx_11_0_arm64.whl (178 kB)\n",
      "Downloading pi_heif-0.22.0-cp39-cp39-macosx_14_0_arm64.whl (559 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m559.8/559.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pikepdf-9.8.1-cp39-cp39-macosx_14_0_arm64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Using cached wrapt-1.17.2-cp39-cp39-macosx_11_0_arm64.whl (38 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Downloading pypandoc-1.15-py3-none-any.whl (21 kB)\n",
      "Using cached pypdf-5.6.0-py3-none-any.whl (304 kB)\n",
      "Downloading pypdfium2-4.30.1-py3-none-macosx_11_0_arm64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Downloading rapidfuzz-3.13.0-cp39-cp39-macosx_11_0_arm64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n",
      "Using cached torchvision-0.22.1-cp39-cp39-macosx_11_0_arm64.whl (1.9 MB)\n",
      "Downloading unstructured_client-0.36.0-py3-none-any.whl (195 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading xlrd-2.0.2-py2.py3-none-any.whl (96 kB)\n",
      "Building wheels for collected packages: antlr4-python3-runtime, langdetect\n",
      "\u001b[33m  DEPRECATION: Building 'antlr4-python3-runtime' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'antlr4-python3-runtime'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144590 sha256=764e6b64329940534eda2a84dbbf3287009025449f4877a05152829cb058f573\n",
      "  Stored in directory: /Users/atharva7/Library/Caches/pip/wheels/23/cf/80/f3efa822e6ab23277902ee9165fe772eeb1dfb8014f359020a\n",
      "\u001b[33m  DEPRECATION: Building 'langdetect' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'langdetect'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993332 sha256=73a64adb6bc2630b74a539988c77a195d080f87cf81520363f7d255760208c46\n",
      "  Stored in directory: /Users/atharva7/Library/Caches/pip/wheels/d1/c1/d9/7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
      "Successfully built antlr4-python3-runtime langdetect\n",
      "Installing collected packages: webencodings, pytz, mpmath, flatbuffers, filetype, antlr4-python3-runtime, XlsxWriter, xlrd, wrapt, urllib3, tzdata, typing-inspection, tqdm, sympy, soupsieve, sniffio, safetensors, regex, rapidfuzz, pyyaml, python-multipart, python-magic, python-iso639, pypdfium2, pypdf, pyparsing, pypandoc, pydantic-core, pycparser, pyasn1, protobuf, pillow, olefile, numpy, networkx, mypy-extensions, marshmallow, MarkupSafe, lxml, langdetect, kiwisolver, joblib, importlib-resources, idna, humanfriendly, html5lib, hf-xet, h11, grpcio, fsspec, fonttools, filelock, et-xmlfile, emoji, cycler, click, charset_normalizer, chardet, certifi, cachetools, backoff, annotated-types, aiofiles, unstructured.pytesseract, typing-inspect, scipy, rsa, requests, python-pptx, python-oxmsg, python-docx, pydantic, pycocotools, pyasn1-modules, proto-plus, pi-heif, pdf2image, pandas, openpyxl, opencv-python, onnx, omegaconf, nltk, markdown, jinja2, httpcore, googleapis-common-protos, Deprecated, contourpy, coloredlogs, cffi, beautifulsoup4, anyio, torch, requests-toolbelt, pikepdf, onnxruntime, matplotlib, huggingface-hub, httpx, grpcio-status, google-auth, dataclasses-json, cryptography, unstructured-client, torchvision, tokenizers, pdfminer.six, google-api-core, accelerate, unstructured, transformers, timm, unstructured-inference, google-cloud-vision, effdet\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116/116\u001b[0m [effdet] [google-cloud-vision]s]re]ent]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Deprecated-1.2.18 MarkupSafe-3.0.2 XlsxWriter-3.2.5 accelerate-1.7.0 aiofiles-24.1.0 annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 anyio-4.9.0 backoff-2.2.1 beautifulsoup4-4.13.4 cachetools-5.5.2 certifi-2025.6.15 cffi-1.17.1 chardet-5.2.0 charset_normalizer-3.4.2 click-8.1.8 coloredlogs-15.0.1 contourpy-1.3.0 cryptography-45.0.4 cycler-0.12.1 dataclasses-json-0.6.7 effdet-0.4.1 emoji-2.14.1 et-xmlfile-2.0.0 filelock-3.18.0 filetype-1.2.0 flatbuffers-25.2.10 fonttools-4.58.4 fsspec-2025.5.1 google-api-core-2.25.1 google-auth-2.40.3 google-cloud-vision-3.10.2 googleapis-common-protos-1.70.0 grpcio-1.73.0 grpcio-status-1.73.0 h11-0.16.0 hf-xet-1.1.4 html5lib-1.1 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.33.0 humanfriendly-10.0 idna-3.10 importlib-resources-6.5.2 jinja2-3.1.6 joblib-1.5.1 kiwisolver-1.4.7 langdetect-1.0.9 lxml-5.4.0 markdown-3.8 marshmallow-3.26.1 matplotlib-3.9.4 mpmath-1.3.0 mypy-extensions-1.1.0 networkx-3.2.1 nltk-3.9.1 numpy-2.0.2 olefile-0.47 omegaconf-2.3.0 onnx-1.18.0 onnxruntime-1.19.2 opencv-python-4.11.0.86 openpyxl-3.1.5 pandas-2.3.0 pdf2image-1.17.0 pdfminer.six-20250506 pi-heif-0.22.0 pikepdf-9.8.1 pillow-11.2.1 proto-plus-1.26.1 protobuf-6.31.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 pycocotools-2.0.10 pycparser-2.22 pydantic-2.11.7 pydantic-core-2.33.2 pypandoc-1.15 pyparsing-3.2.3 pypdf-5.6.0 pypdfium2-4.30.1 python-docx-1.2.0 python-iso639-2025.2.18 python-magic-0.4.27 python-multipart-0.0.20 python-oxmsg-0.0.2 python-pptx-1.0.2 pytz-2025.2 pyyaml-6.0.2 rapidfuzz-3.13.0 regex-2024.11.6 requests-2.32.4 requests-toolbelt-1.0.0 rsa-4.9.1 safetensors-0.5.3 scipy-1.13.1 sniffio-1.3.1 soupsieve-2.7 sympy-1.14.0 timm-1.0.15 tokenizers-0.21.1 torch-2.7.1 torchvision-0.22.1 tqdm-4.67.1 transformers-4.52.4 typing-inspect-0.9.0 typing-inspection-0.4.1 tzdata-2025.2 unstructured-0.17.2 unstructured-client-0.36.0 unstructured-inference-1.0.5 unstructured.pytesseract-0.3.15 urllib3-2.4.0 webencodings-0.5.1 wrapt-1.17.2 xlrd-2.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install \"unstructured[all-docs]\" pydantic pillow lxml matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11578d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa9920cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pdf_elements = partition_pdf(\n",
    "    filename=\"Data/Transformer Architecture explained _ by Amanatullah _ Medium.pdf\",\n",
    "    strategy=\"hi_res\",\n",
    "    extract_images_in_pdf=True,\n",
    "    extract_image_block_types=[\"Image\",\"Table\"],\n",
    "    extract_image_block_to_payload=False,\n",
    "    extract_image_block_output_dir=\"extracted_data\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b80608d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.Header at 0x32b0f27c0>,\n",
       " <unstructured.documents.elements.Header at 0x32b0f26d0>,\n",
       " <unstructured.documents.elements.Header at 0x32af23490>,\n",
       " <unstructured.documents.elements.Title at 0x32af3ba60>,\n",
       " <unstructured.documents.elements.Title at 0x32af3b100>,\n",
       " <unstructured.documents.elements.Title at 0x32af3b700>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32af23910>,\n",
       " <unstructured.documents.elements.Title at 0x1765b3a00>,\n",
       " <unstructured.documents.elements.Title at 0x3140ef850>,\n",
       " <unstructured.documents.elements.Title at 0x127127cd0>,\n",
       " <unstructured.documents.elements.Title at 0x32af3bd90>,\n",
       " <unstructured.documents.elements.Text at 0x329059a60>,\n",
       " <unstructured.documents.elements.Text at 0x329059a90>,\n",
       " <unstructured.documents.elements.Title at 0x329059ac0>,\n",
       " <unstructured.documents.elements.Text at 0x329059970>,\n",
       " <unstructured.documents.elements.Title at 0x32b030a90>,\n",
       " <unstructured.documents.elements.Text at 0x1761e67c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3539a8d30>,\n",
       " <unstructured.documents.elements.Image at 0x1765d7370>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1765d7490>,\n",
       " <unstructured.documents.elements.Header at 0x32af23d90>,\n",
       " <unstructured.documents.elements.Image at 0x32af23be0>,\n",
       " <unstructured.documents.elements.Text at 0x32b22d4c0>,\n",
       " <unstructured.documents.elements.Header at 0x32af23a00>,\n",
       " <unstructured.documents.elements.Header at 0x3539a8ca0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3539a8e20>,\n",
       " <unstructured.documents.elements.Title at 0x1764d0df0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x176db2b80>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1765a8850>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b0f23d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x17659e0a0>,\n",
       " <unstructured.documents.elements.Header at 0x17659ebb0>,\n",
       " <unstructured.documents.elements.Header at 0x176db24c0>,\n",
       " <unstructured.documents.elements.Header at 0x32af23c40>,\n",
       " <unstructured.documents.elements.Image at 0x17659e9d0>,\n",
       " <unstructured.documents.elements.FigureCaption at 0x17659ebe0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x17659e310>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b0fa220>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x17659e1c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32af657c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x17659efd0>,\n",
       " <unstructured.documents.elements.Header at 0x17659ecd0>,\n",
       " <unstructured.documents.elements.Header at 0x1765b3820>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32af65e50>,\n",
       " <unstructured.documents.elements.Title at 0x176e221c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1765cbd90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32af65d60>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32af65190>,\n",
       " <unstructured.documents.elements.Title at 0x176db45b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32af655b0>,\n",
       " <unstructured.documents.elements.Title at 0x1761f5070>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b159af0>,\n",
       " <unstructured.documents.elements.Title at 0x176df4f40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32afc1520>,\n",
       " <unstructured.documents.elements.Title at 0x1764df880>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32afc1760>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b0301f0>,\n",
       " <unstructured.documents.elements.ListItem at 0x32afc1d30>,\n",
       " <unstructured.documents.elements.Title at 0x32b176b50>,\n",
       " <unstructured.documents.elements.ListItem at 0x32afc1b80>,\n",
       " <unstructured.documents.elements.ListItem at 0x32afc1dc0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b17bac0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b17b280>,\n",
       " <unstructured.documents.elements.Header at 0x32af65130>,\n",
       " <unstructured.documents.elements.Header at 0x32af655e0>,\n",
       " <unstructured.documents.elements.Header at 0x32afc1400>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32afc1e80>,\n",
       " <unstructured.documents.elements.Image at 0x32afc1ac0>,\n",
       " <unstructured.documents.elements.FigureCaption at 0x17659e130>,\n",
       " <unstructured.documents.elements.Title at 0x32b17be50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b17b640>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b0301c0>,\n",
       " <unstructured.documents.elements.Header at 0x32b0303d0>,\n",
       " <unstructured.documents.elements.Header at 0x32b030a00>,\n",
       " <unstructured.documents.elements.Header at 0x1765d7f40>,\n",
       " <unstructured.documents.elements.Image at 0x32af65df0>,\n",
       " <unstructured.documents.elements.Title at 0x176df46d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x176df42b0>,\n",
       " <unstructured.documents.elements.Image at 0x176df4550>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x176df4400>,\n",
       " <unstructured.documents.elements.Title at 0x176df4700>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1765dfd90>,\n",
       " <unstructured.documents.elements.Header at 0x176e3aca0>,\n",
       " <unstructured.documents.elements.Header at 0x176df4250>,\n",
       " <unstructured.documents.elements.Header at 0x176df4520>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32afc1a60>,\n",
       " <unstructured.documents.elements.Text at 0x32b176c10>,\n",
       " <unstructured.documents.elements.Image at 0x1765dfd00>,\n",
       " <unstructured.documents.elements.FigureCaption at 0x1765df040>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1765dfa00>,\n",
       " <unstructured.documents.elements.Header at 0x1765df760>,\n",
       " <unstructured.documents.elements.Header at 0x32af65940>,\n",
       " <unstructured.documents.elements.Header at 0x1765df280>,\n",
       " <unstructured.documents.elements.Title at 0x1765df370>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1765dfbe0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1764bf6d0>,\n",
       " <unstructured.documents.elements.Title at 0x353a0f4f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b1a6250>,\n",
       " <unstructured.documents.elements.Text at 0x32b176d60>,\n",
       " <unstructured.documents.elements.Title at 0x32b28b9d0>,\n",
       " <unstructured.documents.elements.Title at 0x32b28b280>,\n",
       " <unstructured.documents.elements.Title at 0x32b28bdc0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1765e3580>,\n",
       " <unstructured.documents.elements.Header at 0x1765e3310>,\n",
       " <unstructured.documents.elements.Header at 0x1765df130>,\n",
       " <unstructured.documents.elements.Header at 0x176df4970>,\n",
       " <unstructured.documents.elements.Image at 0x1765e33d0>,\n",
       " <unstructured.documents.elements.FigureCaption at 0x1765e35b0>,\n",
       " <unstructured.documents.elements.Title at 0x176e10f70>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x176e10d00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x176e10550>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b28b8e0>,\n",
       " <unstructured.documents.elements.ListItem at 0x176e10820>,\n",
       " <unstructured.documents.elements.ListItem at 0x176e10700>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x176e10d90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b269eb0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b269910>,\n",
       " <unstructured.documents.elements.Header at 0x176e10790>,\n",
       " <unstructured.documents.elements.Header at 0x176e10340>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b1bcdc0>,\n",
       " <unstructured.documents.elements.Image at 0x32b269fa0>,\n",
       " <unstructured.documents.elements.FigureCaption at 0x32b269f10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b269b50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b269100>,\n",
       " <unstructured.documents.elements.Title at 0x32b269280>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b269460>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b2698e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b269640>,\n",
       " <unstructured.documents.elements.Header at 0x32b269af0>,\n",
       " <unstructured.documents.elements.Header at 0x32b2694f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b1598b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1764df6d0>,\n",
       " <unstructured.documents.elements.Title at 0x32b28b820>,\n",
       " <unstructured.documents.elements.Image at 0x32af976d0>,\n",
       " <unstructured.documents.elements.FigureCaption at 0x1765cbcd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1761c4c40>,\n",
       " <unstructured.documents.elements.Title at 0x1761c4df0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1761c40d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1761c4220>,\n",
       " <unstructured.documents.elements.Header at 0x1764df820>,\n",
       " <unstructured.documents.elements.Header at 0x176e10490>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1761c4c10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1761c46a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1761c4820>,\n",
       " <unstructured.documents.elements.Title at 0x353a457f0>,\n",
       " <unstructured.documents.elements.Title at 0x353a452b0>,\n",
       " <unstructured.documents.elements.Title at 0x32b15d280>,\n",
       " <unstructured.documents.elements.Title at 0x353a45df0>,\n",
       " <unstructured.documents.elements.Title at 0x353a2eeb0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1761ed760>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1761edee0>,\n",
       " <unstructured.documents.elements.Header at 0x176e02f40>,\n",
       " <unstructured.documents.elements.Header at 0x1761c4880>,\n",
       " <unstructured.documents.elements.Image at 0x32b269a30>,\n",
       " <unstructured.documents.elements.Title at 0x1761ed8b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1761ddee0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1761dd310>,\n",
       " <unstructured.documents.elements.Title at 0x32b28b2e0>,\n",
       " <unstructured.documents.elements.Image at 0x32b28b4c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b28ba00>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b28bd00>,\n",
       " <unstructured.documents.elements.Image at 0x32b28b940>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b28b1c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b28b220>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x176146fd0>,\n",
       " <unstructured.documents.elements.Text at 0x353a2ed00>,\n",
       " <unstructured.documents.elements.Title at 0x32b2640d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b22df40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b22da30>,\n",
       " <unstructured.documents.elements.Text at 0x32b264d90>,\n",
       " <unstructured.documents.elements.Title at 0x32b264700>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32afce340>,\n",
       " <unstructured.documents.elements.Image at 0x32afce460>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32afce640>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32afce820>,\n",
       " <unstructured.documents.elements.Header at 0x1761ed3a0>,\n",
       " <unstructured.documents.elements.Title at 0x353a15ca0>,\n",
       " <unstructured.documents.elements.Text at 0x353a15ee0>,\n",
       " <unstructured.documents.elements.Header at 0x1761ddd30>,\n",
       " <unstructured.documents.elements.Header at 0x32b28b460>,\n",
       " <unstructured.documents.elements.Text at 0x353a15d30>,\n",
       " <unstructured.documents.elements.Text at 0x353a15610>,\n",
       " <unstructured.documents.elements.Title at 0x353a4c9d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a4c070>,\n",
       " <unstructured.documents.elements.Title at 0x1761c4670>,\n",
       " <unstructured.documents.elements.Image at 0x32afce280>,\n",
       " <unstructured.documents.elements.Image at 0x32afce610>,\n",
       " <unstructured.documents.elements.Image at 0x32b15dfd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b15d100>,\n",
       " <unstructured.documents.elements.Image at 0x32b15da60>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b15d7c0>,\n",
       " <unstructured.documents.elements.Title at 0x32b15d850>,\n",
       " <unstructured.documents.elements.Title at 0x32b15d940>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b15d3d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b15d220>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b15d610>,\n",
       " <unstructured.documents.elements.Title at 0x353a4c040>,\n",
       " <unstructured.documents.elements.Text at 0x353a4ce20>,\n",
       " <unstructured.documents.elements.Text at 0x353a4c340>,\n",
       " <unstructured.documents.elements.Text at 0x353a4c460>,\n",
       " <unstructured.documents.elements.Text at 0x353a4cb80>,\n",
       " <unstructured.documents.elements.Image at 0x32b056fd0>,\n",
       " <unstructured.documents.elements.Image at 0x32b056220>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b056af0>,\n",
       " <unstructured.documents.elements.Title at 0x353a4c580>,\n",
       " <unstructured.documents.elements.Text at 0x353a4c3d0>,\n",
       " <unstructured.documents.elements.Header at 0x32b22ddc0>,\n",
       " <unstructured.documents.elements.Header at 0x32afce9d0>,\n",
       " <unstructured.documents.elements.Image at 0x32b15dbb0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b056eb0>,\n",
       " <unstructured.documents.elements.Image at 0x32b15de50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b0564f0>,\n",
       " <unstructured.documents.elements.Title at 0x1761ed160>,\n",
       " <unstructured.documents.elements.Title at 0x353a4c5b0>,\n",
       " <unstructured.documents.elements.Title at 0x1761d8e50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a561c0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a560a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a0fcd0>,\n",
       " <unstructured.documents.elements.Title at 0x1761d88e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a56670>,\n",
       " <unstructured.documents.elements.Text at 0x1761d89a0>,\n",
       " <unstructured.documents.elements.Text at 0x1761d89d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a0f430>,\n",
       " <unstructured.documents.elements.Title at 0x353a0f5e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a0f220>,\n",
       " <unstructured.documents.elements.Title at 0x32b0f22b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a0fac0>,\n",
       " <unstructured.documents.elements.Header at 0x32b056fa0>,\n",
       " <unstructured.documents.elements.Header at 0x353a56d00>,\n",
       " <unstructured.documents.elements.Image at 0x353a56b20>,\n",
       " <unstructured.documents.elements.Image at 0x353a0fb50>,\n",
       " <unstructured.documents.elements.Image at 0x353a0f1f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a45730>,\n",
       " <unstructured.documents.elements.Image at 0x32b28b8b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a45a60>,\n",
       " <unstructured.documents.elements.Title at 0x353a455b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a45040>,\n",
       " <unstructured.documents.elements.Title at 0x353a45820>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a45f10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a45250>,\n",
       " <unstructured.documents.elements.Title at 0x1761d83a0>,\n",
       " <unstructured.documents.elements.Text at 0x1761edb50>,\n",
       " <unstructured.documents.elements.Title at 0x1761eddc0>,\n",
       " <unstructured.documents.elements.Text at 0x1761ed0d0>,\n",
       " <unstructured.documents.elements.Text at 0x353a56be0>,\n",
       " <unstructured.documents.elements.Text at 0x353a56850>,\n",
       " <unstructured.documents.elements.Image at 0x353a15ac0>,\n",
       " <unstructured.documents.elements.Image at 0x353a15c70>,\n",
       " <unstructured.documents.elements.Image at 0x353a15970>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a15b50>,\n",
       " <unstructured.documents.elements.Image at 0x353a15d60>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a2e7c0>,\n",
       " <unstructured.documents.elements.Title at 0x353a2efa0>,\n",
       " <unstructured.documents.elements.Title at 0x353a2ec10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a2ea30>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a2e820>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b2641f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b264f10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b264760>,\n",
       " <unstructured.documents.elements.Title at 0x353a566d0>,\n",
       " <unstructured.documents.elements.Title at 0x32af764f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b2643d0>,\n",
       " <unstructured.documents.elements.Header at 0x353a45fa0>,\n",
       " <unstructured.documents.elements.Header at 0x353a0fe80>,\n",
       " <unstructured.documents.elements.Image at 0x353a45280>,\n",
       " <unstructured.documents.elements.Image at 0x353a15760>,\n",
       " <unstructured.documents.elements.Image at 0x353a15b20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b264340>,\n",
       " <unstructured.documents.elements.Image at 0x353a2e850>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a2ea90>,\n",
       " <unstructured.documents.elements.Title at 0x32b264af0>,\n",
       " <unstructured.documents.elements.Title at 0x32b15d880>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a4c8e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a4c850>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a4c0a0>,\n",
       " <unstructured.documents.elements.Title at 0x32af76730>,\n",
       " <unstructured.documents.elements.Text at 0x32af76790>,\n",
       " <unstructured.documents.elements.Title at 0x32af767f0>,\n",
       " <unstructured.documents.elements.Title at 0x32af76850>,\n",
       " <unstructured.documents.elements.Text at 0x32af76880>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a4c400>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a4c430>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a4c730>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_pdf_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65891939",
   "metadata": {},
   "outputs": [],
   "source": [
    "Header = []\n",
    "Footer = []\n",
    "Title = []\n",
    "NarrativeText = []\n",
    "Text = []\n",
    "ListItem = []\n",
    "\n",
    "\n",
    "for element in raw_pdf_elements:\n",
    "    if \"unstructured.documents.elements.Header\" in str(type(element)):\n",
    "        Header.append(str(element))\n",
    "    elif \"unstructured.documents.elements.Footer\" in str(type(element)):\n",
    "        Footer.append(str(element))  \n",
    "    elif \"unstructured.documents.elements.Title\" in str(type(element)):\n",
    "        Title.append(str(element)) \n",
    "    elif \"unstructured.documents.elements.NarrativeText\" in str(type(element)):\n",
    "        NarrativeText.append(str(element))\n",
    "    elif \"unstructured.documents.elements.Text\" in str(type(element)):\n",
    "        Text.append(str(element))\n",
    "    elif \"unstructured.documents.elements.ListItem\" in str(type(element)):\n",
    "        ListItem.append(str(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bbedaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Write',\n",
       " 'Transformers are a new development in machine learning that have been making a lot of noise lately. They are incredibly good at keeping track of context, and this is why the text that they write makes sense. In this chapter, we will go over their architecture and how they work.',\n",
       " 'https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c',\n",
       " 'Transformer models are one of the most exciting new developments in machine learning. They were introduced in the paper Attention is All You Need. Transformers can be used to write stories, essays, poems, answer questions, translate between languages, chat with humans, and they can even pass exams that are hard for humans! But what are they? You’ll be happy to know that the architecture of transformer models is not that complex, it simply is a concatenation of some very useful components, each of which has its own function. In this chapter, you will learn all of these',\n",
       " 'In a nutshell, what does a transformer do? Imagine that you’re writing a text message on your phone. After each word, you may get three words suggested to you. For example, if you type “Hello, how are”, the phone may suggest words such as “you”, or “your” as the next word. Of course, if you continue selecting the suggested word in your phone, you’ll quickly find that the message formed by these words makes no sense. If you look at each set of 3 or 4 consecutive words, it may make sense, but these words don’t concatenate to anything with a meaning. This is because the model used in the phone doesn’t carry the overall context of the message, it simply predicts which word is more likely to come up after the last few. Transformers, on the other hand, keep track of the context of what is being written, and this is',\n",
       " 'why the text that they write makes sense.',\n",
       " 'The phone can suggest the next word to use in a text message, but does not have the power to generate coherent text.',\n",
       " 'https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c',\n",
       " 'I have to be honest with you, the first time I found out that transformers build text one word at a time, I couldn’t believe it. First of all, this is not how humans form sentences and thoughts. We first form a basic thought, and then start refining it and adding words to it. This is also not how ML models do other things. For example, images are not built this way. Most neural network based graphical models form a rough version of the image, and slowly refine it or add detail until it is perfect. So why would a transformer model build text word by word? One answer is, because that works really well. A more satisfying one is that because transformers are so incredibly good at keeping track of the context, that the next word they pick is exactly',\n",
       " 'what it needs to keep going with an idea.',\n",
       " 'And how are transformers trained? With a lot of data, all the data on the internet, in fact. So when you input the sentence “Hello, how are” into the transformer, it simply knows that, based on all the text in the internet, the best next word is “you”. If you were to give it a more complicated command, say, “Write a story.”, it may figure out that a good next word to use is “Once”. Then it adds this word to the command, and figures out that a good next',\n",
       " 'https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c',\n",
       " '3/17',\n",
       " 'word is “upon”, and so on. And word by word, it will continue until it writes a',\n",
       " 'Command: Write a story.',\n",
       " 'Response: Once',\n",
       " 'Next command: Write a story. Once',\n",
       " 'Next command: Write a story. Once upon',\n",
       " 'Next command: Write a story. Once upon a',\n",
       " 'Next command: Write a story. Once upon a time',\n",
       " 'Now that we know what transformers do, let’s get to their architecture. If you’ve seen the architecture of a transformer model, you may have jumped in awe like I did the first time I saw it, it looks quite complicated! However, when you break it down into its most important parts, it’s not so bad. The',\n",
       " 'transformer has 4 main parts:',\n",
       " 'https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c',\n",
       " '4/17',\n",
       " 'The fourth one, the transformer block, is the most complex of all. Many of these can be concatenated, and each one contains two main parts: The attention and the feedforward components.',\n",
       " 'Tokenization is the most basic step. It consists of a large dataset of tokens, including all the words, punctuation signs, etc. The tokenization step takes every word, prefix, suffix, and punctuation signs, and sends them to a known token from the library.',\n",
       " 'https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c',\n",
       " 'Once the input has been tokenized, it’s time to turn words into numbers. For this, we use an embedding. In a previous chapter you learned about how text embeddings send every piece of text to a vector (a list) of numbers. If two pieces of text are similar, then the numbers in their corresponding vectors are similar to each other (componentwise, meaning each pair of numbers in the same position are similar). Otherwise, if two pieces of text are different, then the numbers in their corresponding vectors are different.',\n",
       " 'In general embeddings send every word (token) to a long list of numbers.',\n",
       " 'https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c',\n",
       " 'Once we have the vectors corresponding to each of the tokens in the sentence, the next step is to turn all these into one vector to process. The most common way to turn a bunch of vectors into one vector is to add them, componentwise. That means, we add each coordinate separately. For example, if the vectors (of length 2) are [1,2], and [3,4], their corresponding sum is [1+3, 2+4], which equals [4, 6]. This can work, but there’s a small caveat. Addition is commutative, meaning that if you add the same numbers in a different order, you get the same result. In that case, the sentence “I’m not sad, I’m happy” and the sentence “I’m not happy, I’m sad”, will result in the same vector, given that they have the same words, except in different order. This is not good. Therefore, we must come up with some method that will give us a different vector for the two sentences. Several methods work, and we’ll go with one of them: positional encoding. Positional encoding consists of adding a sequence of predefined vectors to the embedding vectors of the words. This ensures we get a unique vector for every sentence, and sentences with the same words in different order will be assigned different vectors. In the example below, the vectors corresponding to the words “Write”, “a”, “story”, and “.” become the modified vectors that carry information about their position, labeled “Write (1)”, “a (2)”, “story (3)”, and “.',\n",
       " 'https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c',\n",
       " 'Let’s recap what we have so far. The words come in and get turned into tokens (tokenization), tokenized words are turned into numbers (embeddings), then order gets taken into account (positional encoding). This gives us a vector for every token that we input to the model. Now, the next step is to predict the next word in this sentence. This is done with a really really large neural network, which is trained precisely with that goal, to predict the next word in a sentence.',\n",
       " 'We can train such a large network, but we can vastly improve it by adding a key step: the attention component. Introduced in the seminal paper Attention is All you Need, it is one of the key ingredients in transformer models, and one of the reasons they work so well. Attention is explained in the previous section, but for now, imagine it as a way to add context to each',\n",
       " 'The attention component is added at every block of the feedforward network. Therefore, if you imagine a large feedforward neural network whose goal is to predict the next word, formed by several blocks of smaller neural networks, an attention component is added to each one of these blocks. Each component of the transformer, called a transformer block, is then formed by two main components:',\n",
       " 'https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c',\n",
       " 'The next step is attention. As you learned attention mechanism deals with a very important problem: the problem of context. Sometimes, as you know, the same word can be used with different meanings. This tends to confuse language models, since an embedding simply sends words to vectors, without knowing which definition of the word they’re using.',\n",
       " 'Attention is a very useful technique that helps language models understand the context. In order to understand how attention works, consider the',\n",
       " 'following two sentences:',\n",
       " 'As you can see, the word ‘bank’ appears in both, but with different definitions. In sentence 1, we are referring to the land at the side of the river, and in the second one to the institution that holds money. The computer has no idea of this, so we need to somehow inject that knowledge into it. What can help us? Well, it seems that the other words in the sentence can come to our rescue. For the first sentence, the words ‘the’, and ‘of’ do us no good. But the word ‘river’ is the one that is letting us know that we’re talking about the land at the side of the river. Similarly, in sentence 2, the word ‘money’ is the',\n",
       " 'https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c',\n",
       " '9/17',\n",
       " 'one that is helping us understand that the word ‘bank’ is now referring to the institution that holds money.',\n",
       " 'In short, what attention does is it moves the words in a sentence (or piece of text) closer in the word embedding. In that way, the word “bank” in the sentence “Money in the bank” will be moved closer to the word “money”. Equivalently, in the sentence “The bank of the river”, the word “bank” will be moved closer to the word “river”. That way, the modified word “bank” in each of the two sentences will carry some of the information of the neighboring words, adding context to it.',\n",
       " 'The attention step used in transformer models is actually much more powerful, and it’s called multi-head attention. In multi-head attention, several different embeddings are used to modify the vectors and add context to them. Multi-head attention has helped language models reach much higher levels of efficacy when processing and generating text.',\n",
       " 'Now that you know that a transformer is formed by many layers of transformer blocks, each containing an attention and a feedforward layer, you can think of it as a large neural network that predicts the next word in a sentence. The transformer outputs scores for all the words, where the',\n",
       " 'https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c',\n",
       " '10/17',\n",
       " 'highest scores are given to the words that are most likely to be next in the sentence.',\n",
       " 'The last step of a transformer is a softmax layer, which turns these scores into probabilities (that add to 1), where the highest scores correspond to the highest probabilities. Then, we can sample out of these probabilities for the next word. In the example below, the transformer gives the highest probability of 0.5 to “Once”, and probabilities of 0.3 and 0.2 to “Somewhere” and “There”. Once we sample, the word “once” is selected, and that’s the',\n",
       " 'Now what? Well, we repeat the step. We now input the text “Write a story. Once” into the model, and most likely, the output will be “upon”. Repeating this step again and again, the transformer will end up writing a story, such as “Once upon a time, there was a …”.',\n",
       " 'https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c',\n",
       " '11/17',\n",
       " 'Now that you know how transformers work, we still have a bit of work to do. Imagine the following: You ask the transformer “What is the capital of Algeria?”. We would love for it to answer “Algiers”, and move on. However, the transformer is trained on the entire internet. The internet is a big place, and it’s not necessarily the best question/answer repository. Many pages, for example, would have long lists of questions without answers. In this case, the next sentence after “What is the capital of Algeria?” could be another question, such as “What is the population of Algeria?”, or “What is the capital of Burkina Faso?”. The transformer is not a human who thinks about their responses, it simply mimics what it sees on the internet (or any dataset that has been provided). So how do we get the transformer to answer questions?',\n",
       " 'The answer is post-training. In the same way that you would teach a person to do certain tasks, you can get a transformer to perform tasks. Once a transformer is trained on the entire internet, then it is trained again on a large dataset which corresponds to lots of questions and their respective answers. Transformers (like humans), have a bias towards the last things they’ve learned, so post-training has proven a very useful step to help transformers succeed at the tasks they are asked to.',\n",
       " 'Post-training also helps with many other tasks. For example, one can post- train a transformer with large datasets of conversations, in order to help it perform well as a chatbot, or to help us write stories, poems, or even code.',\n",
       " 'https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c',\n",
       " '12/17',\n",
       " '919 followers · 35 following',\n",
       " 'I am an AI/ML Developer at Fastor7 Pvt. Ltd.',\n",
       " 'Write a response',\n",
       " 'What are your thoughts?',\n",
       " 'Sandra G Feb 26, 2024',\n",
       " \"Hi there! I thoroughly enjoyed reading your article - it was incredibly informative! Have you ever thought about sharing your insights on a page? We'd love to have your perspective on our platform, The Deep Hub.\",\n",
       " \"If you're interested in becoming an… more\",\n",
       " 'Abhishek Verma Sep 11, 2024',\n",
       " 'Great article.',\n",
       " 'Mehmet Deniz May 21, 2024',\n",
       " 'fantastic article!',\n",
       " 'https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c',\n",
       " 'See all responses',\n",
       " 'Amanatullah',\n",
       " 'Amanatullah',\n",
       " 'Introduction: Bridging the Gap — Understanding Anthropic’s Model Context…',\n",
       " 'As technology continues to advance, machine learning models have become increasingly…',\n",
       " 'Mar 21 32 1',\n",
       " 'https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c',\n",
       " 'Amanatullah',\n",
       " 'Amanatullah',\n",
       " 'Overview',\n",
       " 'Introduction',\n",
       " 'Dec 17, 2024 9',\n",
       " 'Jun 12, 2023 223',\n",
       " 'See all from Amanatullah',\n",
       " 'https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c',\n",
       " '15/17',\n",
       " 'Yashwanth S',\n",
       " 'LM Po',\n",
       " 'When it comes to modern natural language processing (NLP) and sequence-to-sequenc…',\n",
       " 'From Transformers (2017) to DeepSeek-R1 (2025)',\n",
       " 'Dec 24, 2024 1',\n",
       " 'John the Quant',\n",
       " 'In about ai by Edgar Bermudez',\n",
       " 'Hi guys! John the Quant here. In this series of articles, we are going to explore each piece …',\n",
       " 'Large Language Models (LLMs) like GPT, BERT, and similar architectures have…',\n",
       " 'Jan 21 2',\n",
       " 'Jan 28 30',\n",
       " 'https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c',\n",
       " '16/17',\n",
       " 'Paco Sun',\n",
       " 'Yan Xu',\n",
       " 'Customer stories',\n",
       " 'When pretraining meets the real world.',\n",
       " '5d ago',\n",
       " 'See more recommendations',\n",
       " 'https://medium.com/@amanatulla1606/transformer-architecture-explained-2c49e2257b4c',\n",
       " '17/17']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NarrativeText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3caf03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tokenization',\n",
       " 'Positional encoding',\n",
       " 'Transformer block (several of these)',\n",
       " 'Sentence 1: The bank of the river.',\n",
       " 'Sentence 2: Money in the bank.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ListItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b11d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = []\n",
    "\n",
    "for element in raw_pdf_elements:\n",
    "    if \"unstructured.documents.elements.Image\" in str(type(element)):\n",
    "        img.append(str(element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61a1d8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Output Probabilities Attention: weighted mean Query i= simi | | simitariy | => poses ey <==) Relevant info Keys ] Values | C = Gained Previous Memory Stored Information Positional Encoding Hello I love you We Q- KT x ee => K= XWx r— + Attention(Q, K,V) = softmax( Qk Vv vd Vv => Q= XWe Positional Encoding',\n",
       " '',\n",
       " 'Hello how are you feeling this week and your kin S wonderful weekend with your you r things kindness and happiness for your family love you and your kindness Hello, how are Gn (wa fen fies Rte Bye Un i Y and QPStciiieting | gh > Bie wibntimn & CPV PDF a Pin Re) 123 e space return space return',\n",
       " 'Series of transformer blocks',\n",
       " 'Tokenization Write a story. —> B',\n",
       " 'Embedding ‘ve 0.91 0.56 wes 0.23 -1.56 1.34 vee 0.14 2.13 -0.42 | sae -1.03 |',\n",
       " 'Positional encoding 213 | -042 | ... | -1.03 + 2. —B story 156 | 134 |... | o14 | 4 lc ——',\n",
       " 'Transformer block Transformer block Transformer block',\n",
       " 'Attention ian, Money in the bank 9 id D| fia I Money in the bank',\n",
       " 'Transformer Aardvark Somewhere Write a story. There Zygote',\n",
       " '',\n",
       " '',\n",
       " 'a',\n",
       " 'S',\n",
       " 'Before MCP After MCP',\n",
       " '',\n",
       " '&',\n",
       " '',\n",
       " 'Cloud Providers On inaged by external providers like AWS, GCP, Azure. Managed internally wit! pricing, subscription models. High upfront costs for h 2; resources added on demand. s updates, maintenance, and availability. Limited by the physical Requires in-house man ed by providers, compliance tools available. regions and increase capacity. Direct control over sect Customizable for speci',\n",
       " 'Vigniviu. varmommig wraurne tryin c—',\n",
       " '&',\n",
       " '&',\n",
       " 'Cross Attention Positional',\n",
       " 'A Brief History of LLMs 1018 2018 2019 2019 2020 2021 2022 2022 1UN OCT FEB OCT MAY SEP MAR NOV 20232023 2024 2024 a FEB MAR MAR APR dy a GPT FLAN LlaMA BERT GPT-3.5 = Opené GPT-2 InstrutGPT GPT# prado DeePS: ners GPT-3 ChatGPT Deep',\n",
       " 'e',\n",
       " '',\n",
       " 'LLM Flowchart Word Embedding Positional Encoding tention < Skip Connection',\n",
       " '',\n",
       " '@',\n",
       " '',\n",
       " 'Transfer',\n",
       " '',\n",
       " '@',\n",
       " '']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a209303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P11' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P18' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P24' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P30' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P36' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P42' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P48' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P54' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P60' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P66' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P72' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P78' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P84' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P90' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P96' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P102' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P108' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P114' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P120' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P126' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P132' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P138' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P144' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P150' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P156' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P162' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P168' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P174' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P180' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P186' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P192' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P198' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P204' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P210' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P216' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P222' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P228' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P234' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P240' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P246' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P252' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P258' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P264' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P270' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P276' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P282' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P288' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P294' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P300' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P306' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P312' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P318' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P324' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P330' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P336' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P342' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P348' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P354' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P360' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P366' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P372' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P378' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P384' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P390' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P396' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P402' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P408' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P414' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P420' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P426' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P432' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P438' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P444' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P450' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P456' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P462' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P468' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P474' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P480' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P486' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P492' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P498' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P504' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P510' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P516' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P522' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P528' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P534' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P540' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P546' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P552' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P558' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P564' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P570' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P576' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P582' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P588' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P594' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P600' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P606' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P612' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P618' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P624' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P630' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P636' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P642' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P648' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'P654' is an invalid float value\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n",
      "Could get FontBBox from font descriptor because None cannot be parsed as 4 floats\n"
     ]
    }
   ],
   "source": [
    "raw_pdf_elements2 = partition_pdf(\n",
    "    filename=\"Data2/2303.18223v16.pdf\",\n",
    "    strategy=\"hi_res\",\n",
    "    extract_images_in_pdf=True,\n",
    "    extract_image_block_types=[\"Image\",\"Table\"],\n",
    "    extract_image_block_to_payload=False,\n",
    "    extract_image_block_output_dir=\"extracted_data2\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d842cb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<unstructured.documents.elements.Text at 0x1761dd4c0>,\n",
       " <unstructured.documents.elements.Text at 0x32b2a1f10>,\n",
       " <unstructured.documents.elements.Text at 0x32b2a1700>,\n",
       " <unstructured.documents.elements.Text at 0x32b2a1460>,\n",
       " <unstructured.documents.elements.Text at 0x355851880>,\n",
       " <unstructured.documents.elements.Header at 0x343983f40>,\n",
       " <unstructured.documents.elements.Text at 0x355851ac0>,\n",
       " <unstructured.documents.elements.Title at 0x355851760>,\n",
       " <unstructured.documents.elements.Title at 0x355851bb0>,\n",
       " <unstructured.documents.elements.Title at 0x3558517f0>,\n",
       " <unstructured.documents.elements.Title at 0x3558511c0>,\n",
       " <unstructured.documents.elements.Title at 0x355851340>,\n",
       " <unstructured.documents.elements.Title at 0x32b5cef40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b5ce190>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35545aeb0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35545a940>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35545a6d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3565db130>,\n",
       " <unstructured.documents.elements.Title at 0x177265b20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b17b160>,\n",
       " <unstructured.documents.elements.Title at 0x3556672b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x355667490>,\n",
       " <unstructured.documents.elements.Image at 0x35545a3d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35527df10>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35545acd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x355fe44f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x355609460>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x355667d30>,\n",
       " <unstructured.documents.elements.Title at 0x355667be0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3556675e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x356a91610>,\n",
       " <unstructured.documents.elements.Footer at 0x356a919d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x356e143d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b2a12e0>,\n",
       " <unstructured.documents.elements.Title at 0x32b5cefa0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x356a912b0>,\n",
       " <unstructured.documents.elements.Title at 0x356144970>,\n",
       " <unstructured.documents.elements.Formula at 0x356a914f0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x356a91220>,\n",
       " <unstructured.documents.elements.Formula at 0x356a91310>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x356a916a0>,\n",
       " <unstructured.documents.elements.Title at 0x356a91250>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35572c1f0>,\n",
       " <unstructured.documents.elements.Title at 0x32b558940>,\n",
       " <unstructured.documents.elements.Formula at 0x35572c130>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35572c670>,\n",
       " <unstructured.documents.elements.Title at 0x35572c550>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1792ecdf0>,\n",
       " <unstructured.documents.elements.Title at 0x356529640>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3565292e0>,\n",
       " <unstructured.documents.elements.Footer at 0x356529940>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35564d790>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35572c640>,\n",
       " <unstructured.documents.elements.Title at 0x3565298b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x355851610>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35572cbe0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x356a91640>,\n",
       " <unstructured.documents.elements.Title at 0x355423af0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x355423b80>,\n",
       " <unstructured.documents.elements.Title at 0x1765fe3d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x355423a90>,\n",
       " <unstructured.documents.elements.Title at 0x355423e20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x355423580>,\n",
       " <unstructured.documents.elements.Footer at 0x356d183d0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x356a91160>,\n",
       " <unstructured.documents.elements.Title at 0x355423b50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35545a0a0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3564374f0>,\n",
       " <unstructured.documents.elements.Title at 0x356d18130>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x356d18a00>,\n",
       " <unstructured.documents.elements.Title at 0x356d182b0>,\n",
       " <unstructured.documents.elements.Title at 0x356d18220>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x355380d90>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x355380880>,\n",
       " <unstructured.documents.elements.Footer at 0x3553801f0>,\n",
       " <unstructured.documents.elements.FigureCaption at 0x356d18340>,\n",
       " <unstructured.documents.elements.Title at 0x35564d430>,\n",
       " <unstructured.documents.elements.Title at 0x355851c40>,\n",
       " <unstructured.documents.elements.Title at 0x3558512b0>,\n",
       " <unstructured.documents.elements.Table at 0x32af97e50>,\n",
       " <unstructured.documents.elements.Title at 0x3560af340>,\n",
       " <unstructured.documents.elements.Text at 0x355851130>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35643c730>,\n",
       " <unstructured.documents.elements.Title at 0x35643c8e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35643c340>,\n",
       " <unstructured.documents.elements.Title at 0x355693670>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35643c430>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35643c9d0>,\n",
       " <unstructured.documents.elements.Title at 0x1765998e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35643c880>,\n",
       " <unstructured.documents.elements.Text at 0x355851910>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x355604700>,\n",
       " <unstructured.documents.elements.Title at 0x356421640>,\n",
       " <unstructured.documents.elements.Title at 0x35568d2e0>,\n",
       " <unstructured.documents.elements.Title at 0x355851d60>,\n",
       " <unstructured.documents.elements.Image at 0x32af97b50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x17b3a2430>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35643c970>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x356a91130>,\n",
       " <unstructured.documents.elements.Table at 0x35643c070>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x176599c70>,\n",
       " <unstructured.documents.elements.Title at 0x3555998b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x355599b50>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3555995e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x355599850>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x355599100>,\n",
       " <unstructured.documents.elements.Footer at 0x355599520>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x355423c70>,\n",
       " <unstructured.documents.elements.Title at 0x1764eadf0>,\n",
       " <unstructured.documents.elements.Title at 0x354a4bc40>,\n",
       " <unstructured.documents.elements.Table at 0x3555998e0>,\n",
       " <unstructured.documents.elements.FigureCaption at 0x356131490>,\n",
       " <unstructured.documents.elements.Table at 0x356131400>,\n",
       " <unstructured.documents.elements.Title at 0x355851b20>,\n",
       " <unstructured.documents.elements.Title at 0x343948760>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b28ee20>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b28eee0>,\n",
       " <unstructured.documents.elements.Image at 0x32b28ef40>,\n",
       " <unstructured.documents.elements.FigureCaption at 0x32b28edc0>,\n",
       " <unstructured.documents.elements.Title at 0x355a20fa0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x355a209d0>,\n",
       " <unstructured.documents.elements.Footer at 0x355a20970>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3561315e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x32b28ebe0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x355a95ee0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x356131460>,\n",
       " <unstructured.documents.elements.Title at 0x355a20c40>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x355a20c10>,\n",
       " <unstructured.documents.elements.Text at 0x356aa6580>,\n",
       " <unstructured.documents.elements.Title at 0x355a20ac0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x343983fd0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3556b43d0>,\n",
       " <unstructured.documents.elements.Title at 0x3556b4040>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3556b4520>,\n",
       " <unstructured.documents.elements.Title at 0x3556b4eb0>,\n",
       " <unstructured.documents.elements.ListItem at 0x328aa42b0>,\n",
       " <unstructured.documents.elements.ListItem at 0x3556b41c0>,\n",
       " <unstructured.documents.elements.ListItem at 0x355a69e80>,\n",
       " <unstructured.documents.elements.ListItem at 0x3556b4280>,\n",
       " <unstructured.documents.elements.ListItem at 0x356257280>,\n",
       " <unstructured.documents.elements.ListItem at 0x356257190>,\n",
       " <unstructured.documents.elements.Footer at 0x1764ea280>,\n",
       " <unstructured.documents.elements.ListItem at 0x3556b4430>,\n",
       " <unstructured.documents.elements.ListItem at 0x355a69e20>,\n",
       " <unstructured.documents.elements.ListItem at 0x3556b44c0>,\n",
       " <unstructured.documents.elements.ListItem at 0x1764ea220>,\n",
       " <unstructured.documents.elements.ListItem at 0x3556b44f0>,\n",
       " <unstructured.documents.elements.ListItem at 0x1764eafd0>,\n",
       " <unstructured.documents.elements.ListItem at 0x355663ee0>,\n",
       " <unstructured.documents.elements.ListItem at 0x356e20df0>,\n",
       " <unstructured.documents.elements.ListItem at 0x3556634c0>,\n",
       " <unstructured.documents.elements.ListItem at 0x356e20be0>,\n",
       " <unstructured.documents.elements.ListItem at 0x356d32a90>,\n",
       " <unstructured.documents.elements.ListItem at 0x356d328e0>,\n",
       " <unstructured.documents.elements.ListItem at 0x356d329a0>,\n",
       " <unstructured.documents.elements.Footer at 0x355dcf8b0>,\n",
       " <unstructured.documents.elements.ListItem at 0x35565a310>,\n",
       " <unstructured.documents.elements.ListItem at 0x356e20d30>,\n",
       " <unstructured.documents.elements.ListItem at 0x328aa4af0>,\n",
       " <unstructured.documents.elements.ListItem at 0x356d328b0>,\n",
       " <unstructured.documents.elements.ListItem at 0x355dcf880>,\n",
       " <unstructured.documents.elements.ListItem at 0x356d324f0>,\n",
       " <unstructured.documents.elements.ListItem at 0x353a98d30>,\n",
       " <unstructured.documents.elements.ListItem at 0x353a981f0>,\n",
       " <unstructured.documents.elements.ListItem at 0x353a98520>,\n",
       " <unstructured.documents.elements.ListItem at 0x353a982b0>,\n",
       " <unstructured.documents.elements.ListItem at 0x353a98ee0>,\n",
       " <unstructured.documents.elements.ListItem at 0x355936be0>,\n",
       " <unstructured.documents.elements.Footer at 0x353a98460>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x355dcf970>,\n",
       " <unstructured.documents.elements.ListItem at 0x355a69f10>,\n",
       " <unstructured.documents.elements.ListItem at 0x353a98820>,\n",
       " <unstructured.documents.elements.ListItem at 0x353a98340>,\n",
       " <unstructured.documents.elements.ListItem at 0x353a986a0>,\n",
       " <unstructured.documents.elements.ListItem at 0x343948c40>,\n",
       " <unstructured.documents.elements.ListItem at 0x343948430>,\n",
       " <unstructured.documents.elements.ListItem at 0x3439486d0>,\n",
       " <unstructured.documents.elements.ListItem at 0x343948790>,\n",
       " <unstructured.documents.elements.ListItem at 0x3556d2ee0>,\n",
       " <unstructured.documents.elements.ListItem at 0x3556d2940>,\n",
       " <unstructured.documents.elements.ListItem at 0x3556d22b0>,\n",
       " <unstructured.documents.elements.ListItem at 0x3556d2ca0>,\n",
       " <unstructured.documents.elements.Footer at 0x3556d22e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x353a98640>,\n",
       " <unstructured.documents.elements.ListItem at 0x355663e50>,\n",
       " <unstructured.documents.elements.ListItem at 0x343948220>,\n",
       " <unstructured.documents.elements.ListItem at 0x3556d2d30>,\n",
       " <unstructured.documents.elements.ListItem at 0x3556d2220>,\n",
       " <unstructured.documents.elements.ListItem at 0x3556d23d0>,\n",
       " <unstructured.documents.elements.ListItem at 0x328abc7f0>,\n",
       " <unstructured.documents.elements.ListItem at 0x328abcd90>,\n",
       " <unstructured.documents.elements.ListItem at 0x328abc880>,\n",
       " <unstructured.documents.elements.ListItem at 0x328abc8b0>,\n",
       " <unstructured.documents.elements.ListItem at 0x328abcdc0>,\n",
       " <unstructured.documents.elements.ListItem at 0x328abc5b0>,\n",
       " <unstructured.documents.elements.ListItem at 0x356718bb0>,\n",
       " <unstructured.documents.elements.Footer at 0x356718e20>,\n",
       " <unstructured.documents.elements.ListItem at 0x3556d21c0>,\n",
       " <unstructured.documents.elements.ListItem at 0x328abca00>,\n",
       " <unstructured.documents.elements.ListItem at 0x3556d2ac0>,\n",
       " <unstructured.documents.elements.ListItem at 0x328abc700>,\n",
       " <unstructured.documents.elements.ListItem at 0x356718400>,\n",
       " <unstructured.documents.elements.ListItem at 0x356718be0>,\n",
       " <unstructured.documents.elements.ListItem at 0x356718160>,\n",
       " <unstructured.documents.elements.ListItem at 0x3567187f0>,\n",
       " <unstructured.documents.elements.ListItem at 0x343991f40>,\n",
       " <unstructured.documents.elements.ListItem at 0x343991af0>,\n",
       " <unstructured.documents.elements.Footer at 0x343991bb0>,\n",
       " <unstructured.documents.elements.ListItem at 0x356718dc0>,\n",
       " <unstructured.documents.elements.ListItem at 0x353a98370>,\n",
       " <unstructured.documents.elements.ListItem at 0x3439912e0>,\n",
       " <unstructured.documents.elements.Header at 0x343991c70>,\n",
       " <unstructured.documents.elements.Title at 0x328abceb0>,\n",
       " <unstructured.documents.elements.Title at 0x343991100>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3439919a0>,\n",
       " <unstructured.documents.elements.Title at 0x3439916d0>,\n",
       " <unstructured.documents.elements.Image at 0x343991160>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x343991040>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3553ee610>,\n",
       " <unstructured.documents.elements.Title at 0x3553ee370>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x17931fbb0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x356aa6190>,\n",
       " <unstructured.documents.elements.Footer at 0x356aa63a0>,\n",
       " <unstructured.documents.elements.Title at 0x343991940>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x17931f5b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3553ee850>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x356aa6f40>,\n",
       " <unstructured.documents.elements.Title at 0x356aa68e0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x356a95d00>,\n",
       " <unstructured.documents.elements.Title at 0x356a95460>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x356a95af0>,\n",
       " <unstructured.documents.elements.Title at 0x356a95dc0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x3539d0fd0>,\n",
       " <unstructured.documents.elements.Footer at 0x1792e13d0>,\n",
       " <unstructured.documents.elements.FigureCaption at 0x32b1764c0>,\n",
       " <unstructured.documents.elements.Table at 0x356a958b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x356a95880>,\n",
       " <unstructured.documents.elements.Title at 0x1792e18b0>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x1792e1160>,\n",
       " <unstructured.documents.elements.Title at 0x35569a610>,\n",
       " <unstructured.documents.elements.NarrativeText at 0x35569a940>,\n",
       " <unstructured.documents.elements.Header at 0x35569a580>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_pdf_elements2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7641af33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
